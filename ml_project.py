# -*- coding: utf-8 -*-
"""ml project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1reO_PFclO5CWq63-tfn07V--VqT4ST4e
"""

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

# Step 1.1: Load the Data
# Upload the Excel file from your local machine
from google.colab import files
uploaded = files.upload()  # Use this to upload your Excel file

# Assuming the file is named 'student_data.xlsx'
df = pd.read_excel('/content/student_data (1) (1).xlsx')

# Display first few rows to understand the data structure
print("First few rows of the dataset:")
print(df.head())

# Step 1.2: Clean Data
# Drop irrelevant columns (if any), for example, "Student ID" and "Name"
df = df.drop(['Student ID', 'Name'], axis=1, errors='ignore')

# Check for any missing values
print("\nMissing values in each column:")
print(df.isnull().sum())

# Step 1.3: Encode Categorical Data
# Instantiate encoders
one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')  # Updated sparse to sparse_output
label_encoder = LabelEncoder()

# One-hot encode categorical columns: 'Field', 'Technical Skills', 'Soft Skills', 'Internships', 'Project Names'
# For demonstration, let's assume we only encode 'Field' here
# Repeat this for other categorical columns as needed
encoded_fields = one_hot_encoder.fit_transform(df[['Field']])
encoded_fields_df = pd.DataFrame(encoded_fields, columns=one_hot_encoder.get_feature_names_out(['Field']))

# Concatenate the encoded fields back to the main dataframe and drop the original 'Field' column
df = pd.concat([df, encoded_fields_df], axis=1)
df = df.drop(['Field'], axis=1)

# Convert binary column 'Placement Ready' to numerical (1 for Yes, 0 for No)
df['Placement Ready'] = df['Placement Ready'].map({'Yes': 1, 'No': 0})

# Encode target fields with LabelEncoder: 'Best Field for student' and 'Best Job Role'
df['Best Field for Placement'] = label_encoder.fit_transform(df['Best Field for Placement'])
df['Best Job Role'] = label_encoder.fit_transform(df['Best Job Role'])

# Step 1.4: Split Data for Multiple Predictions
# Preparing different feature (X) and target (y) datasets for each target variable

# Data for "Placement Ready" Prediction
X_ready = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_ready = df['Placement Ready']
X_train_ready, X_test_ready, y_train_ready, y_test_ready = train_test_split(X_ready, y_ready, test_size=0.2, random_state=42)

# Data for "Best Field for Placement" Prediction
X_field = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_field = df['Best Field for Placement']
X_train_field, X_test_field, y_train_field, y_test_field = train_test_split(X_field, y_field, test_size=0.2, random_state=42)

# Data for "Best Job Role" Prediction
X_role = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_role = df['Best Job Role']
X_train_role, X_test_role, y_train_role, y_test_role = train_test_split(X_role, y_role, test_size=0.2, random_state=42)

print("\nData split successfully for multiple predictions.")

from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the Excel data
df = pd.read_excel('/content/student_data (1) (1).xlsx')

# Drop unnecessary columns like 'Student ID' and 'Name'
df = df.drop(['Student ID', 'Name'], axis=1, errors='ignore')

# Convert Placement Ready to binary
df['Placement Ready'] = df['Placement Ready'].map({'Yes': 1, 'No': 0})

# Initialize OneHotEncoder with `sparse_output=False`
one_hot_encoder = OneHotEncoder(sparse_output=False)

# Function to apply OneHotEncoding to categorical columns
def encode_column(df, column_name):
    # Fit and transform the column
    encoded_data = one_hot_encoder.fit_transform(df[[column_name]])
    encoded_df = pd.DataFrame(encoded_data, columns=one_hot_encoder.get_feature_names_out([column_name]))
    df = df.join(encoded_df)
    df = df.drop(column_name, axis=1)
    return df

# Encode all categorical columns except target columns
categorical_columns = ['Field', 'Technical Skills', 'Soft Skills', 'Internships', 'Project Names']
for col in categorical_columns:
    df = encode_column(df, col)

# Encode target fields with LabelEncoder: 'Best Field for Placement' and 'Best Job Role'
label_encoder = LabelEncoder()
df['Best Field for Placement'] = label_encoder.fit_transform(df['Best Field for Placement'])
df['Best Job Role'] = label_encoder.fit_transform(df['Best Job Role'])

# Split data for each target prediction
# "Placement Ready" prediction
X_ready = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_ready = df['Placement Ready']
X_train_ready, X_test_ready, y_train_ready, y_test_ready = train_test_split(X_ready, y_ready, test_size=0.2, random_state=42)

# "Best Field for Placement" prediction
X_field = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_field = df['Best Field for Placement']
X_train_field, X_test_field, y_train_field, y_test_field = train_test_split(X_field, y_field, test_size=0.2, random_state=42)

# "Best Job Role" prediction
X_role = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_role = df['Best Job Role']
X_train_role, X_test_role, y_train_role, y_test_role = train_test_split(X_role, y_role, test_size=0.2, random_state=42)

print("\nData preprocessing and splitting done successfully.")

# Function to train and evaluate the Random Forest model
def train_evaluate_model(X_train, X_test, y_train, y_test, target_name):
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    accuracy = accuracy_score(y_test, predictions)
    report = classification_report(y_test, predictions)

    print(f"\n--- {target_name} Prediction ---")
    print(f"Accuracy: {accuracy:.2f}")
    print(f"Classification Report:\n{report}")

    return model

# Train and evaluate models for each target

# Step 2.1: Placement Ready Prediction
rf_ready = train_evaluate_model(X_train_ready, X_test_ready, y_train_ready, y_test_ready, "Placement Ready")

# Step 2.2: Best Field for Placement Prediction
rf_field = train_evaluate_model(X_train_field, X_test_field, y_train_field, y_test_field, "Best Field for Placement")

# Step 2.3: Best Job Role Prediction
rf_role = train_evaluate_model(X_train_role, X_test_role, y_train_role, y_test_role, "Best Job Role")

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the Excel data
df = pd.read_excel('/content/student_data (1) (1).xlsx')

# Drop unnecessary columns like 'Student ID' and 'Name'
df = df.drop(['Student ID', 'Name'], axis=1, errors='ignore')

# Convert Placement Ready to binary
df['Placement Ready'] = df['Placement Ready'].map({'Yes': 1, 'No': 0})

# Initialize OneHotEncoder with `sparse_output=False`
one_hot_encoder = OneHotEncoder(sparse_output=False)

# Function to apply OneHotEncoding to categorical columns
def encode_column(df, column_name):
    # Fit and transform the column
    encoded_data = one_hot_encoder.fit_transform(df[[column_name]])
    encoded_df = pd.DataFrame(encoded_data, columns=one_hot_encoder.get_feature_names_out([column_name]))
    df = df.join(encoded_df)
    df = df.drop(column_name, axis=1)
    return df

# Encode all categorical columns except target columns
categorical_columns = ['Field', 'Technical Skills', 'Soft Skills', 'Internships', 'Project Names']
for col in categorical_columns:
    df = encode_column(df, col)

# Encode target fields with LabelEncoder: 'Best Field for Placement' and 'Best Job Role'
label_encoder = LabelEncoder()
df['Best Field for Placement'] = label_encoder.fit_transform(df['Best Field for Placement'])
df['Best Job Role'] = label_encoder.fit_transform(df['Best Job Role'])

# Split data for each target prediction
# "Placement Ready" prediction
X_ready = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_ready = df['Placement Ready']
X_train_ready, X_test_ready, y_train_ready, y_test_ready = train_test_split(X_ready, y_ready, test_size=0.2, random_state=42)

# "Best Field for Placement" prediction
X_field = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_field = df['Best Field for Placement']
X_train_field, X_test_field, y_train_field, y_test_field = train_test_split(X_field, y_field, test_size=0.2, random_state=42)

# "Best Job Role" prediction
X_role = df.drop(['Placement Ready', 'Best Field for Placement', 'Best Job Role'], axis=1)
y_role = df['Best Job Role']
X_train_role, X_test_role, y_train_role, y_test_role = train_test_split(X_role, y_role, test_size=0.2, random_state=42)

print("\nData preprocessing and splitting done successfully.")

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Function to train, predict, and evaluate the model
def train_evaluate_model(X_train, X_test, y_train, y_test, target_name):
    # Initialize the model
    model = RandomForestClassifier(random_state=42)

    # Train the model
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    print(f"--- {target_name} Prediction ---")
    print(f"Accuracy: {accuracy:.2f}")
    print("Classification Report:")
    print(report)

    return model

# Step 2.1: Train and evaluate the model for "Placement Ready" Prediction
rf_ready = train_evaluate_model(X_train_ready, X_test_ready, y_train_ready, y_test_ready, "Placement Ready")

# Step 2.2: Train and evaluate the model for "Best Field for Placement" Prediction
rf_field = train_evaluate_model(X_train_field, X_test_field, y_train_field, y_test_field, "Best Field for Placement")

# Step 2.3: Train and evaluate the model for "Best Job Role" Prediction
rf_role = train_evaluate_model(X_train_role, X_test_role, y_train_role, y_test_role, "Best Job Role")

# Function to display feature importance
def display_feature_importance(model, feature_names, target_name):
    importances = model.feature_importances_
    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

    print(f"\n--- Feature Importance for {target_name} Prediction ---")
    print(feature_importance_df.head(10))  # Display top 10 features

# Display feature importance for each prediction
display_feature_importance(rf_ready, X_train_ready.columns, "Placement Ready")
display_feature_importance(rf_field, X_train_field.columns, "Best Field for Placement")
display_feature_importance(rf_role, X_train_role.columns, "Best Job Role")

import joblib

# Save each model to a file
joblib.dump(rf_ready, "placement_ready_model.pkl")
joblib.dump(rf_field, "best_field_model.pkl")
joblib.dump(rf_role, "best_job_role_model.pkl")

print("Models saved successfully.")

import matplotlib.pyplot as plt
import seaborn as sns

# Visualize Feature Importances for "Placement Ready" model
importances = rf_ready.feature_importances_
sorted_indices = np.argsort(importances)[::-1]
plt.figure(figsize=(10,6))
plt.title("Feature Importance for Placement Ready Prediction")
plt.bar(range(X_train_ready.shape[1]), importances[sorted_indices], align="center")
plt.xticks(range(X_train_ready.shape[1]), X_train_ready.columns[sorted_indices], rotation=90)
plt.show()

# Check attributes to verify training completion
print("Classes in Placement Ready Model:", rf_ready.n_classes_)
print("Features in Placement Ready Model:", rf_ready.n_features_in_)

# Use a sample from the training set to test prediction
sample = X_train_ready.iloc[[0]]  # Taking the first row from training data
predicted = rf_ready.predict(sample)
print("Predicted Placement Ready status:", predicted)
print("Actual Placement Ready status:", y_train_ready.iloc[0])

# Visualize Feature Importances for "Best Field for Placement" model
importances = rf_field.feature_importances_
sorted_indices = np.argsort(importances)[::-1]
plt.figure(figsize=(10,6))
plt.title("Feature Importance for Best Field for Placement Prediction")
plt.barh(X_train_field.columns[sorted_indices], importances[sorted_indices])
plt.show()

# Visualize Feature Importances for "Best Job Role" model
importances = rf_role.feature_importances_
sorted_indices = np.argsort(importances)[::-1]
plt.figure(figsize=(10,6))
plt.title("Feature Importance for Best Job Role Prediction")
plt.barh(X_train_role.columns[sorted_indices], importances[sorted_indices])
plt.show()

rf_ready = joblib.load("placement_ready_model.pkl")
rf_field = joblib.load("best_field_model.pkl")
rf_role = joblib.load("best_job_role_model.pkl")

df

# @title Project Names vs Backlogs

from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['Backlogs'].value_counts()
    for x_label, grp in df.groupby('Project Names')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('Project Names')
_ = plt.ylabel('Backlogs')



# @title Internships

from matplotlib import pyplot as plt
import seaborn as sns
df.groupby('Internships').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Project Names

from matplotlib import pyplot as plt
import seaborn as sns
df.groupby('Project Names').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Project Names vs CGPA

from matplotlib import pyplot as plt
import seaborn as sns
figsize = (12, 1.2 * len(df['Project Names'].unique()))
plt.figure(figsize=figsize)
sns.violinplot(df, x='CGPA', y='Project Names', inner='box', palette='Dark2')
sns.despine(top=True, right=True, bottom=True, left=True)

# @title CGPA

from matplotlib import pyplot as plt
df['CGPA'].plot(kind='hist', bins=20, title='CGPA')
plt.gca().spines[['top', 'right',]].set_visible(False)

pip install pandas scikit-learn openpyxl

!pip install joblib

import joblib

import numpy as np
from sklearn.preprocessing import StandardScaler
import joblib

# Example training data (X_train): [CGPA, Projects Completed, Skills, Internships, Certifications, Coding Proficiency]
X_train = np.array([
    [8.5, 3, 1, 1, 1, 1],
    [7.8, 2, 0, 1, 1, 0],
    [6.5, 1, 1, 0, 0, 0],
    [9.0, 4, 1, 1, 1, 1],
    [7.2, 2, 1, 0, 1, 0]
])

# Fit and transform the training data using StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Now you can save the scaler (if needed) and use it later
joblib.dump(scaler, 'scaler.pkl')

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Example target labels (y_train) indicating placement readiness (1 = ready, 0 = not ready)
y_train = np.array([1, 0, 0, 1, 1])

# Train the model
model = RandomForestClassifier()
model.fit(X_train_scaled, y_train)

# Save the model
joblib.dump(model, 'placement_ready_model.pkl')

import numpy as np
import joblib

# Load the trained model and scaler
model = joblib.load('placement_ready_model.pkl')  # Load the trained model
scaler = joblib.load('scaler.pkl')  # Load the scaler

# Input data for one student (e.g., CGPA, projects completed, skills, etc.)
student_data = [8.5, 3, 1, 1, 1, 1]  # Example data

# Preprocess the input data (e.g., scaling)
student_data = np.array(student_data).reshape(1, -1)
student_data = scaler.transform(student_data)  # Apply the scaler

# Predict placement readiness
placement_prediction = model.predict(student_data)

# Display the result
if placement_prediction[0] == 1:
    print("The student is ready for placement.")
else:
    print("The student is not ready for placement.")

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib

# Example training data for job role prediction (make sure both X and y have the same number of rows)
X = np.array([
    [8.5, 4, 3, 2, 1],  # Features: [CGPA, Projects, Coding skills, Internships, Certifications]
    [7.0, 2, 2, 1, 1],
    [6.5, 1, 2, 0, 0],
    [9.0, 5, 4, 2, 2],
    [7.2, 3, 1, 1, 1]
])

# Target variable: Best Job Role (Software Developer, Marketing Manager, etc.)
y_role = ['Android Developer', 'Marketing Manager', 'Data Analyst', 'Data Scientist', 'Product Manager']

# Preprocessing and scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_role, test_size=0.2, random_state=42)

# Train a Random Forest Classifier for job role prediction
model_role = RandomForestClassifier()
model_role.fit(X_train, y_train)

# Save the job role prediction model
joblib.dump(model_role, 'best_role_model.pkl')
joblib.dump(scaler, 'scaler_for_role.pkl')

# To predict the job role for a new student:
new_student_data = np.array([[8.2, 3, 3, 2, 1]])  # Example student data
new_student_data_scaled = scaler.transform(new_student_data)  # Apply the scaler
role_prediction = model_role.predict(new_student_data_scaled)

print(f"The best job role for this student is: {role_prediction[0]}")

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib

# Example training data for job role prediction (make sure both X and y have the same number of rows)
X = np.array([
    [8.5, 4, 3, 2, 1],  # Features: [CGPA, Projects, Coding skills, Internships, Certifications]
    [7.0, 2, 2, 1, 1],
    [6.5, 1, 2, 0, 0],
    [9.0, 5, 4, 2, 2],
    [7.2, 3, 1, 1, 1]
])

# Target variable: Best Job Role (Software Developer, Marketing Manager, etc.)
y_role = ['Software Developer', 'Marketing Manager', 'Data Analyst', 'Data Scientist', 'Product Manager']

# Preprocessing and scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_role, test_size=0.2, random_state=42)

# Train a Random Forest Classifier for job role prediction
model_role = RandomForestClassifier()
model_role.fit(X_train, y_train)

# Save the job role prediction model
joblib.dump(model_role, 'best_role_model.pkl')
joblib.dump(scaler, 'scaler_for_role.pkl')

# To predict the job role for a new student:
new_student_data = np.array([[8.2, 3, 3, 2, 1]])  # Example student data
new_student_data_scaled = scaler.transform(new_student_data)  # Apply the scaler
role_prediction = model_role.predict(new_student_data_scaled)

print(f"The best job role for this student is: {role_prediction[0]}")

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Sample data
data = {
    'Education_Level': ['Bachelors', 'Masters', 'Bachelors', 'PhD', 'Masters', 'Bachelors', 'PhD', 'Masters'],
    'Field_of_Study': ['Computer Science', 'Data Science', 'Engineering', 'Physics', 'Business', 'Data Science', 'Physics', 'Engineering'],
    'Skills': ['Python, Data Analysis', 'Machine Learning, Python', 'Java, Web Development',
               'Data Science, Python, AI', 'Business Analysis, Python', 'Python, Data Analysis',
               'Data Science, AI', 'Machine Learning, Python'],
    'Work_Experience_Years': [1, 3, 2, 4, 5, 2, 5, 3],
    'Industry_Preference': ['Technology', 'Finance', 'Technology', 'Healthcare', 'Finance', 'Technology', 'Healthcare', 'Finance'],
    'Career_Path': ['Data Scientist', 'Data Scientist', 'Software Engineer', 'AI Researcher', 'Business Analyst',
                    'Data Analyst', 'AI Researcher', 'Data Scientist']
}

# Convert data to a DataFrame
df = pd.DataFrame(data)

# Check column names
print(df.columns)

# Initialize LabelEncoder
label_encoder_education = LabelEncoder()
label_encoder_field = LabelEncoder()
label_encoder_skills = LabelEncoder()
label_encoder_industry = LabelEncoder()
label_encoder_career = LabelEncoder()

# Apply encoding consistently
df['Education_Level'] = label_encoder_education.fit_transform(df['Education_Level'])
df['Field_of_Study'] = label_encoder_field.fit_transform(df['Field_of_Study'])
df['Skills'] = label_encoder_skills.fit_transform(df['Skills'])
df['Industry_Preference'] = label_encoder_industry.fit_transform(df['Industry_Preference'])
df['Career_Path'] = label_encoder_career.fit_transform(df['Career_Path'])

# Print the DataFrame to see the encoded data
print(df.head())